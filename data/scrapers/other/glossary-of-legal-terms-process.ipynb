{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This code sample shows Prebuilt Layout operations with the Azure Form Recognizer client library. \n",
    "The async versions of the samples require Python 3.6 or later.\n",
    "\n",
    "To learn more, please visit the documentation - Quickstart: Form Recognizer Python client library SDKs\n",
    "https://learn.microsoft.com/azure/applied-ai-services/form-recognizer/quickstarts/get-started-v3-sdk-rest-api?view=doc-intel-3.1.0&pivots=programming-language-python\n",
    "\"\"\"\n",
    "\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.formrecognizer import DocumentAnalysisClient\n",
    "import os\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "import dotenv\n",
    "\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "# Set the values of your computer vision endpoint and computer vision key\n",
    "# as environment variables:\n",
    "try:\n",
    "    endpoint = os.environ[\"AZURE_COGNITIVE_ENDPOINT\"]\n",
    "    key = os.environ[\"AZURE_COGNITIVE_API_KEY\"]\n",
    "except KeyError:\n",
    "    print(\"Missing environment variable 'VISION_ENDPOINT' or 'VISION_KEY'\")\n",
    "    print(\"Set them before running this sample.\")\n",
    "    exit()\n",
    "\n",
    "\"\"\"\n",
    "Remember to remove the key from your code when you're done, and never post it publicly. For production, use\n",
    "secure methods to store and access your credentials. For more information, see \n",
    "https://docs.microsoft.com/en-us/azure/cognitive-services/cognitive-services-security?tabs=command-line%2Ccsharp#environment-variables-and-application-configuration\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# sample document\n",
    "# formUrl = \"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-REST-api-samples/master/curl/form-recognizer/sample-layout.pdf\"\n",
    "formUrl = \"https://www-s3-live.kent.edu/s3fs-root/s3fs-public/file/Legal%20Glossary%20English%20Arabic%202020%20%282%29.pdf?VersionId=OMDkAUHJ0A2UeXeK3ykrZGITJNcFIxJg\"\n",
    "\n",
    "document_analysis_client = DocumentAnalysisClient(\n",
    "    endpoint=endpoint, credential=AzureKeyCredential(key)\n",
    ")\n",
    "\n",
    "\n",
    "poller = document_analysis_client.begin_analyze_document_from_url(\"prebuilt-layout\", formUrl)\n",
    "result = poller.result()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = result.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from easydict import EasyDict\n",
    "\n",
    "result = EasyDict(data['analyzeResult'])\n",
    "\n",
    "for idx, style in enumerate(result.styles):\n",
    "    print(\n",
    "        \"Document contains {} content\".format(\n",
    "         \"handwritten\" if style.is_handwritten else \"no handwritten\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "# for page in result.pages:\n",
    "#     for line_idx, line in enumerate(page.lines):\n",
    "#         print(\n",
    "#          \"...Line # {} has text content '{}'\".format(\n",
    "#         line_idx,\n",
    "#         line.content.encode(\"utf-8\")\n",
    "#         )\n",
    "#     )\n",
    "\n",
    "#     for selection_mark in page.selection_marks:\n",
    "#         print(\n",
    "#          \"...Selection mark is '{}' and has a confidence of {}\".format(\n",
    "#          selection_mark.state,\n",
    "#          selection_mark.confidence\n",
    "#          )\n",
    "#     )\n",
    "\n",
    "for table_idx, table in enumerate(result.tables):\n",
    "    print(table)\n",
    "    print(\n",
    "        \"Table # {} has {} rows and {} columns\".format(\n",
    "        table_idx, table['rowCount'], table['columnCount']\n",
    "        )\n",
    "    )\n",
    "        \n",
    "    for cell in table.cells:\n",
    "        print(\n",
    "            \"...table.cells[{}][{}] has content '{}'\".format(\n",
    "            cell.rowIndex,\n",
    "            cell.columnIndex,\n",
    "            cell.content,\n",
    "            )\n",
    "        )\n",
    "\n",
    "print(\"----------------------------------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'result' is the variable containing the data from the API call\n",
    "all_tables = []  # This will store the DataFrame for each table\n",
    "\n",
    "for table_idx, table in enumerate(result.tables):\n",
    "    # print(\"Table # {} has {} rows and {} columns\".format(table_idx, table['rowCount'], table['columnCount']))\n",
    "    \n",
    "    # Create an empty DataFrame\n",
    "    df = pd.DataFrame(index=range(table['rowCount']), columns=range(table['columnCount']))\n",
    "    \n",
    "    for cell in table.cells:\n",
    "        # Place the content in the correct row and column in the DataFrame\n",
    "        df.at[cell.rowIndex, cell.columnIndex] = cell.content\n",
    "    \n",
    "    print(df.shape)\n",
    "    all_tables.append(df)  # Append the DataFrame of this table to the list\n",
    "\n",
    "# Now 'all_tables' contains all the tables as DataFrames\n",
    "# For example, to view the first table you can use:\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df_combined = pd.concat(all_tables, axis=0)\n",
    "# strip all strings\n",
    "df_combined = df_combined.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "\n",
    "# Function to handle text overflow in DataFrame\n",
    "def correct_overflow(df):\n",
    "    rows, cols = df.shape\n",
    "    blacklisted_rows = []\n",
    "    for i in range(rows - 1, 0, -1):  # Start from the last row and go upwards\n",
    "        if i in blacklisted_rows:\n",
    "            continue\n",
    "        if df.iloc[i].isnull().sum() < df.shape[1]:  # Check if row has missing items\n",
    "            for j in range(cols):\n",
    "                if pd.notna(df.iloc[i, j]) and df.iloc[i, j] != '':  # Found the non-empty cell)\n",
    "                    # print(\"detected in row\", i, \"column\", j)\n",
    "                    df.iloc[i-1, j] = str(df.iloc[i-1, j]) + ' ' + str(df.iloc[i, j])  # Append text to the cell above\n",
    "                    df.iloc[i, j] = ''  # Clear the overflowed cell\n",
    "                    blacklisted_rows.append(i-1)\n",
    "                    break\n",
    "\n",
    "\n",
    "correct_overflow(df_combined)\n",
    "# drop all rows with any empty cell (even empty string)\n",
    "df_combined.replace('', np.nan, inplace=True)\n",
    "df_combined = df_combined.dropna(how='any', axis=0)\n",
    "\n",
    "# set first row to be columns header\n",
    "df_combined.columns = df_combined.iloc[0]\n",
    "df_combined = df_combined[1:]\n",
    "df_combined.iloc[-1, -1]\n",
    "df_combined.shape\n",
    "df_combined.to_csv('EN-AR Glossary of Legal Terms.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.dropna().iloc[4, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[3,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame creation for demonstration\n",
    "\n",
    "# Example DataFrame for demonstration\n",
    "data = {\n",
    "    'Column1': ['data3', '',                '',     'data5'],\n",
    "    'Column2': ['data2', '+ 2', '',      ''],\n",
    "    'Column3': ['data1', '',                '+ 1', 'data4']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the original DataFrame\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "print()\n",
    "\n",
    "# Function to correct overflow issues in the DataFrame\n",
    "def correct_overflow(df):\n",
    "    # Loop over each row in reverse order, starting from the second last row\n",
    "    for i in range(df.shape[0] - 2, 0, 1): # row wise\n",
    "        for col in range(df.shape[1] - 1, 0, 1):\n",
    "            # Check if the current row and cell is empty and the row below has text in the same column\n",
    "\n",
    "            if not pd.isna(df.iloc[i, col]) and not pd.isna(df.iloc[i + 1, col]):\n",
    "                print(\"Overflow detected in row\", i, \"column\", col)\n",
    "                # Append the text from the row below to the row above\n",
    "                df.iloc[i, col] = df.iloc[i + 1, col] + df.iloc[i, col]\n",
    "                # Clear the text in the row below after moving it up\n",
    "                # df.iloc[i + 1, col] = None\n",
    "\n",
    "# Function to handle text overflow in DataFrame\n",
    "def correct_overflow(df):\n",
    "    rows, cols = df.shape\n",
    "    blacklisted_rows = []\n",
    "    for i in range(rows - 1, 0, -1):  # Start from the last row and go upwards\n",
    "        if i in blacklisted_rows:\n",
    "            continue\n",
    "        if df.iloc[i].isnull().sum() < df.shape[1]:  # Check if row has missing items\n",
    "            for j in range(cols):\n",
    "                if pd.notna(df.iloc[i, j]) and df.iloc[i, j] != '':  # Found the non-empty cell)\n",
    "                    print(\"detected in row\", i, \"column\", j)\n",
    "                    df.iloc[i-1, j] += ' ' + df.iloc[i, j]  # Append text to the cell above\n",
    "                    df.iloc[i, j] = ''  # Clear the overflowed cell\n",
    "                    blacklisted_rows.append(i-1)\n",
    "                    break\n",
    "\n",
    "# Apply the function to the DataFrame\n",
    "correct_overflow(df)\n",
    "\n",
    "# Display the modified DataFrame\n",
    "print(\"----\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Column1': ['data1', '', '', 'data4'],\n",
    "    'Column2': ['', 'data2 continues below', '', 'data4'],\n",
    "    'Column3': ['data1', '', 'data3 continues from above', 'data4']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Call the function to fix the DataFrame\n",
    "fix_overflow(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.cells[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
